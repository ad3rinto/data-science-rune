{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c83aab",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0cb8f8",
   "metadata": {},
   "source": [
    "![Data Science Workflow](img/ds-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bcead9",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "- **Feature selection** is about selecting attributes that have the greatest impact towards the **problem** you are solving.\n",
    "\n",
    "- Notice: It should be clear that all steps are interconnected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3990585",
   "metadata": {},
   "source": [
    "## Why Feature Selection?\n",
    "- Higher accuracy\n",
    "- Simpler models\n",
    "- Reducing overfitting risk\n",
    "\n",
    "See more details on [wikipedia](https://en.wikipedia.org/wiki/Feature_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5290ee",
   "metadata": {},
   "source": [
    "## Feature Selection Techniques\n",
    "### Filter methods\n",
    "- Independent of Model\n",
    "- Based on scores of statistical\n",
    "- Easy to understand\n",
    "- Good for early feature removal\n",
    "- Low computational requirements\n",
    "\n",
    "#### Examples\n",
    "- [Chi square](https://en.wikipedia.org/wiki/Chi-squared_test)\n",
    "- [Information gain](https://en.wikipedia.org/wiki/Information_gain_in_decision_trees)\n",
    "- [Correlation score](https://en.wikipedia.org/wiki/Correlation_coefficient)\n",
    "- [Correlation Matrix with Heatmap](https://vitalflux.com/correlation-heatmap-with-seaborn-pandas/)\n",
    "\n",
    "### Wrapper methods\n",
    "- Compare different subsets of features and run the model on them\n",
    "- Basically a search problem\n",
    "\n",
    "#### Examples\n",
    "- [Best-first search](https://en.wikipedia.org/wiki/Best-first_search)\n",
    "- [Random hill-climbing algorithm](https://en.wikipedia.org/wiki/Hill_climbing)\n",
    "- [Forward selection](https://en.wikipedia.org/wiki/Stepwise_regression)\n",
    "- [Backward elimination](https://en.wikipedia.org/wiki/Stepwise_regression)\n",
    "\n",
    "See more on [wikipedia](https://en.wikipedia.org/wiki/Feature_selection#Subset_selection)\n",
    "\n",
    "### Embedded methods\n",
    "- Find features that contribute most to the accuracy of the model while it is created\n",
    "- Regularization is the most common method - it penalizes higher complexity\n",
    "\n",
    "#### Examples\n",
    "- [LASSO](https://en.wikipedia.org/wiki/Lasso_(statistics))\n",
    "- [Elastic Net](https://en.wikipedia.org/wiki/Elastic_net_regularization)\n",
    "- [Ridge Regression](https://en.wikipedia.org/wiki/Ridge_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88087f41",
   "metadata": {},
   "source": [
    "### Feature Selection Resources\n",
    "- [An Introduction to Feature Selection](https://machinelearningmastery.com/an-introduction-to-feature-selection/)\n",
    "- [Comprehensive Guide on Feature Selection](https://www.kaggle.com/prashant111/comprehensive-guide-on-feature-selection/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03429178",
   "metadata": {},
   "source": [
    "### Before Feature Selection\n",
    "- Clean data (lesson 09)\n",
    "- Divide into training and test set (lesson 10)\n",
    "- Feature scaling (lesson 11)\n",
    "- Only do feature selction on training set\n",
    "    - To avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5d8d0",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "- [Santander Customer Satisfaction](https://www.kaggle.com/c/santander-customer-satisfaction/)\n",
    "    - Which customers are happy customers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed2e94e",
   "metadata": {},
   "source": [
    "## Filter Methods\n",
    "### Constant features\n",
    "- Remove constant features\n",
    "- Constant features add no value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59cebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ca06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533edead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc886f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83adaa48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89e2e0f9",
   "metadata": {},
   "source": [
    "#### Constant features directly with DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0200f704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf261f51",
   "metadata": {},
   "source": [
    "#### Using Sklearn\n",
    "- Remove constant and quasi constant features\n",
    "- [`VarianceThreshold`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html) Feature selector that removes all low-variance features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cb0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc05d92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c8c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4390b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175dd1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f8d65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c48209e8",
   "metadata": {},
   "source": [
    "#### Quasi constant features\n",
    "- Same value for the great majority of the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7965150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05323f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d529adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bce7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a323906e",
   "metadata": {},
   "source": [
    "### Correaltion with color\n",
    "- [`corr()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) Compute pairwise correlation of columns, excluding NA/null values.\n",
    "    - For better readability use: `.style.background_gradient(cmap='Blues')`\n",
    "- Good features are highly correlated with target\n",
    "- Ideally features should be correlated with target, but uncorrelated amont themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2797dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdb3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa4d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f64986c",
   "metadata": {},
   "source": [
    "### Find correlated features\n",
    "- The goal is to find and remove correlated features\n",
    "- Calcualte correlation matrix (assign it to `corr_matrix`)\n",
    "- A feature is correlated to any previous features if the following is true\n",
    "    - Notice that we use correlation 0.8\n",
    "```Python\n",
    "feature = 'imp_op_var39_comer_ult1'\n",
    "(corr_matrix[feature].iloc[:corr_matrix.columns.get_loc(feature)] > 0.8).any()\n",
    "```\n",
    "- Get all the correlated features by using list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d0de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9741760a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a38123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa87e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfd5b6a2",
   "metadata": {},
   "source": [
    "## Wrapper Methods\n",
    "### Forward Selection\n",
    "- [`SequentialFeatureSelector`](http://rasbt.github.io/mlxtend/api_subpackages/mlxtend.feature_selection/#sequentialfeatureselector) Sequential Feature Selection for Classification and Regression.\n",
    "- First install it by running the following in a cell\n",
    "```\n",
    "!pip install mlxtend\n",
    "```\n",
    "- For preparation remove all quasi-constant features and correlated features\n",
    "```Python\n",
    "X = data.drop(['TARGET'] + quasi_features + corr_features, axis=1)\n",
    "y = data['TARGET']\n",
    "```\n",
    "- To demonstrate this we create a small training set\n",
    "```Python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.75, random_state=42)\n",
    "```\n",
    "- We will use the `SVC` model with the `SequentialFeatureSelector`.\n",
    "    - For two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7176e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c31db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035088ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f13b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30488b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99b15db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5441b94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "384b1152",
   "metadata": {},
   "source": [
    "#### Good score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed41303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494255b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
